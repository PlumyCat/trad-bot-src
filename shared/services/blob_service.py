"""
Service de gestion des blobs Azure Storage pour Azure Functions
Adapt√© du code conteneur existant
"""

import logging
import base64
from datetime import datetime, timedelta, timezone
from typing import Dict, Any, List, Optional, Tuple
from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions
from shared.config import Config

logger = logging.getLogger(__name__)


class BlobService:
    """Service pour la gestion des blobs Azure Storage"""
    container_name = Config.INPUT_CONTAINER

    def __init__(self):
        # Configuration Azure Storage
        self.account_name = Config.AZURE_ACCOUNT_NAME
        self.account_key = Config.AZURE_ACCOUNT_KEY

        if not self.account_name:
            raise ValueError(
                "AZURE_ACCOUNT_NAME environnement variable manquante")
        if not self.account_key:
            raise ValueError(
                "AZURE_ACCOUNT_KEY environnement variable manquante")

        # Assurer le format correct de la cl√©
        if not self.account_key.endswith("=="):
            self.account_key += "=="

        # Noms des conteneurs
        self.input_container = Config.INPUT_CONTAINER
        self.output_container = Config.OUTPUT_CONTAINER

        # Client Blob Storage
        self.blob_service_client = BlobServiceClient(
            account_url=Config.get_storage_url(),
            credential=self.account_key
        )

        logger.info("‚úÖ BlobService initialis√©")

    def prepare_blobs(self, file_content_base64: str, file_name: str, target_language: str) -> Dict[str, str]:
        """
        Pr√©pare les blobs source et cible pour la traduction
        Version synchrone pour Azure Functions
        """
        logger.info(
            f"üìÅ Pr√©paration des blobs pour {file_name} ‚Üí {target_language}")

        try:
            # G√©n√©ration des noms de fichiers avec suffixe de langue
            # Utilisation du nom de fichier fourni pour le blob source
            input_blob_name = file_name
            file_base, file_ext = input_blob_name.rsplit(
                ".", 1) if "." in input_blob_name else (input_blob_name, "")

            # Format am√©lior√©: file_name-fr.docx au lieu de file_name_fr.docx
            output_blob_name = f"{file_base}-{target_language}.{file_ext}" if file_ext else f"{file_base}-{target_language}"

            logger.info(f"üìÑ Fichier source: {input_blob_name}")
            logger.info(f"üìÑ Fichier cible: {output_blob_name}")

            # Nettoyage des anciens fichiers (>1h)
            self._delete_old_files(self.output_container, max_age_hours=1)

            # Suppression du fichier cible s'il existe d√©j√†
            self._check_and_delete_target_blob(
                self.output_container, output_blob_name)

            # Conversion et upload du fichier source
            file_content_binary = base64.b64decode(file_content_base64)
            file_size = len(file_content_binary)

            logger.info(f"üìä Taille du fichier: {file_size / 1024:.1f} KB")

            # Upload du fichier source
            input_blob_client = self.blob_service_client.get_blob_client(
                container=self.input_container,
                blob=input_blob_name
            )

            input_blob_client.upload_blob(
                file_content_binary,
                overwrite=True,
                content_type=self._get_content_type(file_name)
            )

            logger.info("‚úÖ Fichier source upload√© avec succ√®s")

            # G√©n√©ration des URLs SAS
            source_url = self._generate_sas_url(
                self.input_container, input_blob_name, read=True)
            target_url = self._generate_sas_url(
                self.output_container, output_blob_name, write=True)

            return {
                "source_url": source_url,
                "target_url": target_url,
                "input_blob_name": input_blob_name,
                "output_blob_name": output_blob_name
            }

        except Exception as e:
            logger.error(
                f"‚ùå Erreur lors de la pr√©paration des blobs: {str(e)}")
            raise

    def get_translated_file_url(self, output_blob_name: str) -> Optional[str]:
        """
        G√©n√®re une URL de t√©l√©chargement pour le fichier traduit
        """
        from urllib.parse import quote
        try:
            # V√©rifier si le blob existe
            blob_client = self.blob_service_client.get_blob_client(
                container=self.output_container,
                blob=output_blob_name
            )

            if not blob_client.exists():
                logger.warning(
                    f"‚ö†Ô∏è Fichier traduit introuvable: {output_blob_name}")
                return None

            # Encodage correct du nom de fichier dans l'URL
            encoded_blob_name = quote(output_blob_name)

            # G√©n√©rer URL SAS avec permissions de √©criture (valide 24h)
            download_url = self._generate_sas_url(
                self.output_container,
                output_blob_name,
                write=True,
                expiry_hours=24
            )

            # Remplacer le nom du blob dans l'URL par la version encod√©e
            if download_url:
                # On ne touche qu'√† la partie chemin du blob
                parts = download_url.split('/')
                # Cherche le nom du blob √† la fin
                if parts[-1] == output_blob_name:
                    parts[-1] = encoded_blob_name
                    download_url = '/'.join(parts)
                else:
                    # fallback: remplace la premi√®re occurrence brute
                    download_url = download_url.replace(
                        output_blob_name, encoded_blob_name, 1)

            logger.info(
                f"‚úÖ URL de t√©l√©chargement g√©n√©r√©e pour: {output_blob_name}")
            return download_url

        except Exception as e:
            logger.error(f"‚ùå Erreur lors de la g√©n√©ration de l'URL: {str(e)}")
            return None

    def download_translated_file(self, output_blob_name: str) -> Optional[bytes]:
        """
        T√©l√©charge le contenu du fichier traduit
        """
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=self.output_container,
                blob=output_blob_name
            )

            if not blob_client.exists():
                logger.warning(
                    f"‚ö†Ô∏è Fichier traduit introuvable: {output_blob_name}")
                return None

            # T√©l√©chargement du contenu
            blob_data = blob_client.download_blob()
            content = blob_data.readall()

            logger.info(f"‚úÖ Fichier t√©l√©charg√©: {len(content)} bytes")
            return content

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du t√©l√©chargement: {str(e)}")
            return None

    def cleanup_translation_files(self, input_blob_name: str, output_blob_name: str) -> bool:
        """
        Nettoie les fichiers de traduction apr√®s traitement
        """
        try:
            success = True

            # Suppression du fichier source
            try:
                input_blob_client = self.blob_service_client.get_blob_client(
                    container=self.input_container,
                    blob=input_blob_name
                )
                input_blob_client.delete_blob()
                logger.info(f"üóëÔ∏è Fichier source supprim√©: {input_blob_name}")
            except Exception as e:
                logger.warning(
                    f"‚ö†Ô∏è Impossible de supprimer le fichier source: {str(e)}")
                success = False

            # Suppression du fichier cible (optionnel)
            try:
                output_blob_client = self.blob_service_client.get_blob_client(
                    container=self.output_container,
                    blob=output_blob_name
                )
                if output_blob_client.exists():
                    output_blob_client.delete_blob()
                    logger.info(
                        f"üóëÔ∏è Fichier cible supprim√©: {output_blob_name}")
            except Exception as e:
                logger.warning(
                    f"‚ö†Ô∏è Impossible de supprimer le fichier cible: {str(e)}")

            return success

        except Exception as e:
            logger.error(f"‚ùå Erreur lors du nettoyage: {str(e)}")
            return False

    def _generate_sas_url(self, container_name: str, blob_name: str,
                          read: bool = False, write: bool = False,
                          expiry_hours: int = 2) -> str:
        """G√©n√®re une URL SAS pour un blob"""
        # Cr√©e l'objet permission directement
        if write == True:
            permissions = "rw"
        else:
            permissions = "r"
        expiry_time = datetime.now(timezone.utc) + \
            timedelta(hours=expiry_hours)
        sas_token = generate_blob_sas(
            account_name=self.account_name,
            container_name=container_name,
            blob_name=blob_name,
            account_key=self.account_key,
            permission=permissions,
            expiry=expiry_time
        )
        logger.info(
            f"SAS URL g√©n√©r√©e: {Config.get_storage_url()}/{container_name}/{blob_name}?{sas_token}")
        return f"{Config.get_storage_url()}/{container_name}/{blob_name}?{sas_token}"

    def _get_content_type(self, file_name: str) -> str:
        """D√©termine le type MIME d'un fichier"""
        extension = file_name.lower().split(
            '.')[-1] if '.' in file_name else ''

        content_types = {
            'pdf': 'application/pdf',
            'docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            'doc': 'application/msword',
            'pptx': 'application/vnd.openxmlformats-officedocument.presentationml.presentation',
            'ppt': 'application/vnd.ms-powerpoint',
            'xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
            'xls': 'application/vnd.ms-excel',
            'txt': 'text/plain',
            'html': 'text/html',
            'htm': 'text/html',
            'xml': 'application/xml',
            'rtf': 'application/rtf'
        }

        return content_types.get(extension, 'application/octet-stream')

    def _check_and_delete_target_blob(self, container_name: str, blob_name: str) -> bool:
        """V√©rifie et supprime un blob cible s'il existe"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=container_name,
                blob=blob_name
            )

            if blob_client.exists():
                blob_client.delete_blob()
                logger.info(f"üóëÔ∏è Ancien fichier cible supprim√©: {blob_name}")
                return True

            return False

        except Exception as e:
            logger.warning(
                f"‚ö†Ô∏è Erreur lors de la suppression du fichier cible: {str(e)}")
            return False

    def _delete_old_files(self, container_name: str, max_age_hours: int = 1) -> int:
        """Supprime les anciens fichiers du conteneur"""
        try:
            container_client = self.blob_service_client.get_container_client(
                container_name)
            cutoff_time = datetime.now(
                timezone.utc) - timedelta(hours=max_age_hours)
            deleted_count = 0

            blobs = container_client.list_blobs()
            for blob in blobs:
                if blob.last_modified < cutoff_time:
                    try:
                        container_client.delete_blob(blob.name)
                        deleted_count += 1
                        logger.debug(
                            f"üóëÔ∏è Ancien fichier supprim√©: {blob.name}")
                    except Exception as e:
                        logger.warning(
                            f"‚ö†Ô∏è Impossible de supprimer {blob.name}: {str(e)}")

            if deleted_count > 0:
                logger.info(
                    f"üßπ {deleted_count} anciens fichiers supprim√©s du conteneur {container_name}")

            return deleted_count

        except Exception as e:
            logger.error(
                f"‚ùå Erreur lors du nettoyage des anciens fichiers: {str(e)}")
            return 0

    def check_blob_exists(self, blob_name: str) -> bool:
        """V√©rifie si un blob existe dans un container"""
        try:
            blob_client = self.blob_service_client.get_blob_client(
                container=self.container_name,
                blob=blob_name
            )
            return blob_client.exists()
        except Exception as e:
            logger.error(
                f"Erreur lors de la v√©rification du blob {blob_name}: {str(e)}")
            return False

    def prepare_translation_urls(self, input_blob_name: str, target_language: str) -> Dict[str, str]:
        """
        Pr√©pare les URLs pour la traduction d'un blob existant
        Le fichier source est d√©j√† dans le container doc-to-trad
        """

        logger.info(
            f"üîÑ Pr√©paration des URLs pour {input_blob_name} ‚Üí {target_language}")

        try:
            # G√©n√©ration du nom du fichier de sortie √† partir du nom normalis√©
            file_base, file_ext = input_blob_name.rsplit(
                ".", 1) if "." in input_blob_name else (input_blob_name, "")

            # Format: file_name-fr.docx avec limitation de longueur
            lang_suffix = f"-{target_language}"

            # Calculer la longueur maximale pour le nom de base
            max_total_length = 200  # Limite conservatrice
            extension_length = len(f".{file_ext}") if file_ext else 0
            suffix_length = len(lang_suffix)
            max_base_length = max_total_length - extension_length - suffix_length

            # Tronquer le nom de base si n√©cessaire
            if len(file_base) > max_base_length:
                file_base = file_base[:max_base_length]
                logger.warning(
                    f"‚ö†Ô∏è Nom de fichier de base tronqu√© pour √©viter la limite Azure: {len(file_base)} caract√®res")

            output_blob_name = f"{file_base}{lang_suffix}.{file_ext}" if file_ext else f"{file_base}{lang_suffix}"

            logger.info(f"üìÑ Fichier source: {input_blob_name}")
            logger.info(f"üìù Fichier source normalis√©: {input_blob_name}")
            logger.info(f"üìÑ Fichier cible: {output_blob_name}")
            logger.info(
                f"üìè Longueur du nom de fichier cible: {len(output_blob_name)} caract√®res")

            # Nettoyage des anciens fichiers (>1h)
            self._delete_old_files(self.output_container, max_age_hours=1)

            # Suppression du fichier cible s'il existe d√©j√†
            self._check_and_delete_target_blob(
                self.output_container, output_blob_name)

            # G√©n√©ration des SAS URLs
            source_url = self._generate_sas_url(
                self.input_container, input_blob_name, read=True)
            target_url = self._generate_sas_url(
                self.output_container, output_blob_name, write=True)

            logger.info("‚úÖ URLs SAS g√©n√©r√©es")

            return {
                "source_url": source_url,
                "target_url": target_url,
                "input_blob_name": input_blob_name,
                "output_blob_name": output_blob_name,
                "original_file_name": input_blob_name
            }

        except Exception as e:
            logger.error(f"Erreur lors de la pr√©paration des URLs: {str(e)}")
            raise
